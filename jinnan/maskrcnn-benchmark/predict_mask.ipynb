{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import cv2\n",
    "from skimage.io import imsave\n",
    "import torch\n",
    "from maskrcnn_benchmark.config import cfg\n",
    "from predictor import COCODemo\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from maskrcnn_benchmark.layers import nms as _box_nms\n",
    "\n",
    "if not os.path.exists('result'):\n",
    "    os.mkdir('result')\n",
    "    \n",
    "if not os.path.exists('result_resize'):\n",
    "    os.mkdir('result_resize')\n",
    "    \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "def load_image_into_numpy_array(image):\n",
    "    (im_width, im_height) = image.size\n",
    "    return np.array(image.getdata()).reshape(\n",
    "        (im_height, im_width, 3)).astype(np.uint8)\n",
    "\n",
    "def load_image_into_numpy_array_resize(image,k):\n",
    "    (im_width, im_height) = image.size\n",
    "    im_width = int(im_width*k)\n",
    "    im_height = int(im_height*k)\n",
    "    \n",
    "    image = image.resize((im_width, im_height), Image.ANTIALIAS)\n",
    "    return np.array(image.getdata()).reshape(\n",
    "        (im_height, im_width, 3)).astype(np.uint8)\n",
    "\n",
    "def predict_save(coco_demo, test_img_fold, test_img_list):\n",
    "    # load image\n",
    "    sub_dict = {}\n",
    "    sub_dict['results'] = []\n",
    "    #for i in range(2):\n",
    "    for i in range(len(test_img_list)):\n",
    "        # process image\n",
    "        start = time.time()\n",
    "        # for i in range(1):\n",
    "        img_name = test_img_list[i]\n",
    "        img_path = os.path.join(test_img_fold, img_name)\n",
    "\n",
    "        result = predict_resize_img(coco_demo,img_path)\n",
    "    \n",
    "        boxes = result['boxes']\n",
    "        scores = result['scores']\n",
    "        labels = result['labels']\n",
    "        print(\"processing time: \", time.time() - start)\n",
    "        # correct for image scale\n",
    "        \n",
    "        image_dict = {}\n",
    "        image_dict['filename'] = img_name\n",
    "        image_dict['rects'] = []\n",
    "        \n",
    "        for box, score, label in zip(boxes, scores, labels):\n",
    "            # scores are sorted so we can break\n",
    "            print (box, score, label)\n",
    "            if score < 0.5:\n",
    "                break\n",
    "            box_dict = {}\n",
    "            color = 'red' #label_color(label)\n",
    "            box_dict['xmin'] = int(box[0])\n",
    "            box_dict['ymin'] = int(box[1])\n",
    "            box_dict['xmax'] = int(box[2])\n",
    "            box_dict['ymax'] = int(box[3])\n",
    "            box_dict['label'] = int(label)\n",
    "            box_dict[\"confidence\"] = float(score)\n",
    "            image_dict['rects'].append(box_dict)\n",
    "            \n",
    "        sub_dict['results'].append(image_dict)\n",
    "    with open(\"record.json\",\"w\") as f:\n",
    "        json.dump(sub_dict,f)\n",
    "        print(\"加载入文件完成...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLIP_LEFT_RIGHT = 0\n",
    "FLIP_TOP_BOTTOM = 1\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "color_dict = {1:(255,0,0),2:(0,255,0),3:(0,0,255),4:(255,255,0),5:(0,255,255)}\n",
    "def overlay_boxes(image, boxes,labels):\n",
    "    \"\"\"\n",
    "    Adds the predicted boxes on top of the image\n",
    "\n",
    "    Arguments:\n",
    "        image (np.ndarray): an image as returned by OpenCV\n",
    "        predictions (BoxList): the result of the computation by the model.\n",
    "            It should contain the field `labels`.\n",
    "    \"\"\"\n",
    "#     labels = predictions.get_field(\"labels\")\n",
    "#     boxes = predictions.bbox\n",
    "\n",
    "    colors = [color_dict[int(label)] for label in labels]\n",
    "\n",
    "    for box, color in zip(boxes, colors):\n",
    "        box = box.to(torch.int64)\n",
    "        top_left, bottom_right = box[:2].tolist(), box[2:].tolist()\n",
    "        image = cv2.rectangle(\n",
    "            image, tuple(top_left), tuple(bottom_right), tuple(color), 1\n",
    "        )\n",
    "\n",
    "    return image\n",
    "\n",
    "def predict_single_img(coco_demo,img_path):\n",
    "    image = Image.open(img_path)\n",
    "    # the array based representation of the image will be used later in order to prepare the\n",
    "    image_np = load_image_into_numpy_array(image)  \n",
    "    image_np,predictions = coco_demo.run_on_opencv_image(image_np)\n",
    "    # print(image.shape)\n",
    "    # print(scale)\n",
    "    boxes = predictions.bbox\n",
    "    scores = predictions.get_field(\"scores\")\n",
    "    labels = predictions.get_field(\"labels\")\n",
    "    result['boxes'] = torch.index_select(box_cat,0,keep)\n",
    "    result['scores'] = torch.index_select(score_cat,0,keep)\n",
    "    result['labels'] = torch.index_select(label_cat,0,keep)\n",
    "    print (result)\n",
    "    result['size'] = image.size\n",
    "    imsave('result/'+img_path.split('/')[-1], image_np)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(image_np)\n",
    "    plt.show()\n",
    "    return result\n",
    "\n",
    "def predict_resize_img(coco_demo,img_path):\n",
    "    boxlist = []\n",
    "    scorelist = []\n",
    "    labellist = []\n",
    "    img_name = img_path.split('/')[-1].split('.')\n",
    "    for k in [0.5,1,2]:#[0.5,0.75,1,1.5,2]:\n",
    "        image = Image.open(img_path)\n",
    "        (im_width, im_height) = image.size\n",
    "        # the array based representation of the image will be used later in order to prepare the\n",
    "        image_np = load_image_into_numpy_array_resize(image,k)  \n",
    "        re,predictions = coco_demo.run_on_opencv_image(image_np)\n",
    "        #imsave('result_resize/'+img_name[0]+'_'+str(k)+'.'+img_name[1], re)\n",
    "        boxes = predictions.resize((im_width, im_height)).bbox\n",
    "        scores = predictions.get_field(\"scores\")\n",
    "        labels = predictions.get_field(\"labels\")\n",
    "        \n",
    "        boxlist.append(boxes)\n",
    "        scorelist.append(scores)\n",
    "        labellist.append(labels)\n",
    "    \n",
    "    for i in range(3):\n",
    "        image = Image.open(img_path)\n",
    "        if i == 1:\n",
    "            image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        elif i == 2:\n",
    "            image = image.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "        (im_width, im_height) = image.size\n",
    "        k = 800./min(im_width, im_height)\n",
    "        image_np = load_image_into_numpy_array_resize(image,k)\n",
    "        re,predictions = coco_demo.run_on_opencv_image(image_np)\n",
    "        if i==0:\n",
    "            #imsave('result_resize/'+img_name[0]+'_normal.'+img_name[1], re)\n",
    "            boxes = predictions.resize((im_width, im_height)).bbox\n",
    "        elif i ==1:\n",
    "            #imsave('result_resize/'+img_name[0]+'_lr.'+img_name[1], re)\n",
    "            boxes = predictions.transpose(FLIP_LEFT_RIGHT).resize((im_width, im_height)).bbox\n",
    "        elif i ==2:\n",
    "            #imsave('result_resize/'+img_name[0]+'_tb.'+img_name[1], re)\n",
    "            boxes = predictions.transpose(FLIP_TOP_BOTTOM).resize((im_width, im_height)).bbox\n",
    "        scores = predictions.get_field(\"scores\")\n",
    "        labels = predictions.get_field(\"labels\")\n",
    "        boxlist.append(boxes)\n",
    "        scorelist.append(scores)\n",
    "        labellist.append(labels)\n",
    "        \n",
    "    box_cat = torch.cat(boxlist,0)\n",
    "    score_cat = torch.cat(scorelist,0)\n",
    "    label_cat = torch.cat(labellist,0)\n",
    "    image = Image.open(img_path)\n",
    "    nms_thresh = 0.5\n",
    "    keep = _box_nms(box_cat, score_cat, nms_thresh)\n",
    "    result = {}\n",
    "    scores = torch.index_select(score_cat,0,keep)\n",
    "    boxes = torch.index_select(box_cat,0,keep)\n",
    "    labels = torch.index_select(label_cat,0,keep)\n",
    "    result['boxes'] = boxes[scores>0.5]\n",
    "    result['scores'] = scores[scores>0.5]\n",
    "    result['labels'] = labels[scores>0.5]\n",
    "    #print (result)\n",
    "    result['size'] = image.size\n",
    "    image_np=load_image_into_numpy_array(image)\n",
    "    image_np = overlay_boxes(image_np, result['boxes'],result['labels'])\n",
    "    imsave('result/'+img_path.split('/')[-1], image_np)\n",
    "    #plt.figure(figsize=(12, 8))\n",
    "    #plt.imshow(image_np)\n",
    "    #plt.show()\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"../configs/e2e_faster_rcnn_X_101_32x8d_FPN_1x_val.yaml\"\n",
    "# update the config options with the config file\n",
    "cfg.merge_from_file(config_file)\n",
    "# manual override some options\n",
    "cfg.merge_from_list([\"MODEL.DEVICE\", \"cuda\"])\n",
    "\n",
    "coco_demo = COCODemo(\n",
    "    cfg,\n",
    "    min_image_size=800,\n",
    "    confidence_threshold=0.7,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_save(coco_demo, test_img_fold, test_img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(model.summary())\n",
    "#\n",
    "#labels_to_names = {1: 't', 2: 'h', 3: 'd', 4: 'd', 5: 'j'}\n",
    "# load label to names mapping for visualization purposes\n",
    "labels_to_names = {0: 'tieke', 1: 'heiding',\n",
    "                   2: 'daoju', 3: 'dian', 4: 'jiandao'}\n",
    "\n",
    "test_img_fold = '/home/hywel/Documents/maskrcnn-benchmark/datasets/coco/rest'\n",
    "#test_img_fold = '/home/hywel/Documents/keras-retinanet/keras_retinanet/CSV/jinnan2_round1_test_a_20190306'\n",
    "test_img_list = os.listdir(test_img_fold)\n",
    "print(len(test_img_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_annotations_file = '/home/hywel/Documents/maskrcnn-benchmark/datasets/coco/annotations/train_argument.json'\n",
    "def xywh_xyxy(box):\n",
    "    box2 = []\n",
    "    for i in range(len(box)):\n",
    "        box2.append( [box[i][0],box[i][1],box[i][0]+box[i][2],box[i][1]+box[i][3]] )\n",
    "    \n",
    "    return box2\n",
    "def find_gt(image_name,img_fold,annotations_file):\n",
    "    with open(annotations_file,'r') as load_f:\n",
    "        groundtruth_data = json.load(load_f)\n",
    "    images = groundtruth_data['images']\n",
    "    annotations = groundtruth_data['annotations']\n",
    "    image_data = None\n",
    "    for image in images:\n",
    "        if image_name == image['file_name']:\n",
    "            image_data = image\n",
    "            break\n",
    "    if not image_data: \n",
    "        print ('can not find image')\n",
    "        return\n",
    "    boxes = []\n",
    "    labels = []\n",
    "    minAreaRects = []\n",
    "    for annotation in annotations:\n",
    "        if annotation['image_id'] == image_data['id']:\n",
    "            boxes.append(annotation['bbox'])\n",
    "            labels.append(annotation['category_id'])\n",
    "            minAreaRects.append(annotation['minAreaRect'])\n",
    "            \n",
    "    result={}\n",
    "    result['boxes'] = torch.tensor(xywh_xyxy(boxes))\n",
    "    result['minAreaRects'] = minAreaRects\n",
    "    result['labels'] = torch.tensor(labels)\n",
    "    #print (result)\n",
    "    result['size'] = (image_data[\"width\"],image_data[\"height\"])\n",
    "    print (image_name)\n",
    "    image = Image.open(img_fold+'/'+image_name)\n",
    "    image_np=load_image_into_numpy_array(image)\n",
    "    image_np = overlay_boxes(image_np, result['boxes'],result['labels'])\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(image_np)\n",
    "    plt.show()\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    find_gt(test_img_list[i],test_img_fold,train_annotations_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#增强对比度\n",
    "def contrast_brightness_image(src1, a, g):\n",
    "    h, w, ch = src1.shape#获取shape的数值，height和width、通道\n",
    " \n",
    "    #新建全零图片数组src2,将height和width，类型设置为原图片的通道类型(色素全为零，输出为全黑图片)\n",
    "    src2 = np.zeros([h, w, ch], src1.dtype)\n",
    "    dst = cv2.addWeighted(src1, a, src2, 1-a, g)#addWeighted函数说明如下\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(dst[..., -1::-1])\n",
    "    plt.show()\n",
    "\n",
    "def equalize_clahe_image(image_path):\n",
    "    print (image_path)\n",
    "    img = cv2.imread(image_path)#.convert('RGB')\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(img[..., -1::-1])\n",
    "    plt.show()\n",
    "    contrast_brightness_image(img, 1.2, 10)\n",
    "    \n",
    "equalize_clahe_image(test_img_fold+'/'+test_img_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
